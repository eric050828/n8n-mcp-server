'''
Defines MCP prompts for guiding user interactions with the n8n server.
'''
from typing import Any
from mcp_server import app

# Note: Prompt functions will be registered in main.py using app.prompt_manager.add_prompt

@app.prompt()
def general_assistance_prompt() -> list[dict[str, str]]:
    """
    Comprehensive introduction to the n8n workflow automation assistant capabilities.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# n8n Workflow Automation Assistant\n\n"
                "Welcome to the n8n Workflow Automation Assistant. This system provides programmatic access to n8n's workflow automation capabilities through a structured API. Below is a comprehensive overview of available operations:\n\n"
                "## Workflow Management\n\n"
                "```\n"
                "list_workflows      - Retrieve workflows with optional filtering by activation status, tags, or name\n"
                "get_workflow        - Obtain complete workflow definition including nodes, connections, and settings\n"
                "create_workflow     - Construct new workflow with custom processing logic and configuration\n"
                "update_workflow     - Modify existing workflow structure, settings, or metadata\n"
                "delete_workflow     - Remove a workflow from the system\n"
                "activate_workflow   - Enable workflow execution\n"
                "deactivate_workflow - Disable workflow execution\n"
                "```\n\n"
                "## Node Discovery & Analysis\n\n"
                "```\n"
                "list_nodes          - Enumerate available node types by category or classification\n"
                "get_node_info       - Retrieve detailed node definition and configuration specifications\n"
                "```\n\n"
                "## Execution Monitoring\n\n"
                "```\n"
                "list_workflow_executions - View execution history for a specific workflow with status filtering\n"
                "get_execution            - Inspect detailed execution record including results and diagnostics\n"
                "delete_execution         - Remove execution history record\n"
                "```\n\n"
                "## Resource Access\n\n"
                "```\n"
                "n8n:/workflow/{workflow_id} - Direct access to workflow definition data\n"
                "n8n:/node-types             - Comprehensive node type registry information\n"
                "n8n:/tags                   - System tag definitions for organization and filtering\n"
                "```\n\n"
                "## Implementation Note\n\n"
                "When creating or modifying workflows, this system enforces strict adherence to the `n8n-sdk-python` data models, particularly:\n\n"
                "- `Node` - Processing step definition with type, parameters, and position\n"
                "- `Connection` - Inter-node data flow specification\n"
                "- `WorkflowSettings` - Execution behavior configuration\n"
                "- `WorkflowStaticData` - Persistent state between executions\n\n"
                "## Usage Examples\n\n"
                "- \"List all active workflows with the 'production' tag\"\n"
                "- \"Retrieve the structure of workflow with ID '7b496ab1-9968-4767-b1d4-fcadc1f24243'\"\n"
                "- \"Create a workflow that fetches data from an API and processes it with a Function node\"\n"
                "- \"Show me execution history for the Customer Onboarding workflow\"\n\n"
                "How may I assist with your workflow automation requirements today?"
            )
        }
    ]

@app.prompt()
def create_workflow_guidance_prompt() -> list[dict[str, str]]:
    """
    Provides structured guidance for workflow creation, precisely aligned with n8n-sdk-python models.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Workflow Creation Guide\n\n"
                "To create a new n8n workflow, the `create_workflow` tool requires parameters that precisely align with the `n8n_sdk_python.models.workflows.WorkflowCreate` model. Below is a comprehensive breakdown of the required and optional parameters:\n\n"
                "## Essential Parameters\n\n"
                "### `name` (string, required)\n"
                "- Descriptive identifier for your workflow\n"
                "- Example: `'API Data Integration Pipeline'`\n\n"
                "### `nodes` (array, required)\n"
                "- Collection of processing steps, each conforming to the `Node` model\n"
                "- Each node requires:\n"
                "  - `name`: Node instance name (string)\n"
                "  - `type`: Node type identifier (string, e.g., `'n8n-nodes-base.httpRequest'`)\n"
                "  - `typeVersion`: Version number (integer or float)\n"
                "  - `position`: Canvas coordinates `[x, y]` (array of floats)\n"
                "  - `parameters`: Configuration object (dictionary)\n"
                "- Optional node properties include:\n"
                "  - `credentials`: Authentication references\n"
                "  - `disabled`: Execution state flag (boolean)\n"
                "  - `notes`: Documentation text (string)\n"
                "  - `onError`: Error handling strategy (string)\n\n"
                "### `connections` (object, optional)\n"
                "- Defines data flow between nodes\n"
                "- Structure: `{ \"SourceNodeName\": { \"main\": [[ { \"node\": \"TargetNodeName\", \"type\": \"main\", \"index\": 0 } ]] } }`\n"
                "- Each source node can connect to multiple targets\n\n"
                "## Optional Configuration\n\n"
                "### `settings` (object, optional)\n"
                "- Execution behavior configuration conforming to `WorkflowSettings` model\n"
                "- Key settings:\n"
                "  - `saveExecutionProgress`: Record execution details (boolean)\n"
                "  - `saveDataErrorExecution`: Error data retention policy (string)\n"
                "  - `saveDataSuccessExecution`: Success data retention policy (string)\n"
                "  - `executionTimeout`: Maximum runtime in seconds (integer)\n"
                "  - `timezone`: Time reference (string, e.g., `'UTC'` or `'Asia/Taipei'`)\n\n"
                "### `static_data` (object, optional)\n"
                "- Persistent state between executions\n"
                "- Typically includes counters or runtime references\n"
                "- Example: `{ \"lastId\": 0 }`\n\n"
                "### `active` (boolean, optional)\n"
                "- Whether to activate the workflow upon creation\n"
                "- Default: `False`\n\n"
                "## Implementation Approach\n\n"
                "1. **Node Discovery**: Use `list_nodes` to explore available node types by category or class\n"
                "2. **Node Configuration**: Examine detailed node specifications with `get_node_info`\n"
                "3. **Connection Design**: Define the logical flow between processing steps\n"
                "4. **Execution Settings**: Configure runtime behavior and persistence policies\n\n"
                "To expedite workflow creation, I can assist you in constructing properly structured parameters based on your functional requirements. What type of workflow would you like to create?"
            )
        }
    ]

@app.prompt()
def discover_node_structure_prompt() -> list[dict[str, str]]:
    """
    Technical guide for discovering and analyzing node definitions for workflow construction.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Node Discovery & Analysis Guide\n\n"
                "## Overview\n\n"
                "To construct properly configured nodes for workflow operations, a systematic approach to node discovery and analysis is essential. This guide outlines the process for identifying available node types and extracting their configuration specifications.\n\n"
                "## Discovery Process\n\n"
                "### Step 1: Enumerate Available Node Types\n\n"
                "Use the `list_nodes` operation to retrieve a comprehensive inventory of available node types:\n\n"
                "```\n"
                "list_nodes(\n"
                "    category: Optional[str] = None,       # Filter by node category (e.g., 'Core Nodes')\n"
                "    node_class: Optional[str] = None,     # Filter by node class (e.g., 'action')\n"
                "    return_types_only: bool = True        # Set False for detailed metadata\n"
                ")\n"
                "```\n\n"
                "#### Example Usage\n\n"
                "```\n"
                "# List all HTTP-related nodes\n"
                "list_nodes(category='Communication')\n"
                "\n"
                "# List all trigger-type nodes\n"
                "list_nodes(node_class='trigger')\n"
                "```\n\n"
                "### Step 2: Analyze Node Definition\n\n"
                "After identifying a node type of interest, retrieve its complete specification using the `get_node_info` operation:\n\n"
                "```\n"
                "get_node_info(node_type: str)  # e.g., 'n8n-nodes-base.httpRequest'\n"
                "```\n\n"
                "## Definition Analysis\n\n"
                "The returned node information contains a `files` dictionary with the node's original definition files. Key file types to analyze include:\n\n"
                "### 1. Node Schema (`*.node.json`)\n\n"
                "- **Name**: The node type identifier\n"
                "- **DisplayName**: User-friendly label for visual representation\n"
                "- **TypeVersion**: Version compatibility specification\n"
                "- **Group**: Categorical classification\n"
                "- **Defaults**: Basic parameter initialization values\n\n"
                "### 2. Description Files (`*.description.ts` or `/descriptions/`)\n\n"
                "Critical for understanding:\n"
                "- **Required parameters**: Essential configuration elements\n"
                "- **Parameter data types**: Expected format for each field\n"
                "- **Options and enumerations**: Valid selections for parameter values\n"
                "- **Parameter dependencies**: Conditional configuration relationships\n"
                "- **Authentication requirements**: Credential specifications\n\n"
                "### 3. Implementation Files (`*.node.ts` or `*.node.js`)\n\n"
                "Reveals:\n"
                "- **Execution logic**: How input is processed\n"
                "- **Dynamic parameters**: Runtime variable handling\n"
                "- **Default behavior**: Implicit operational characteristics\n\n"
                "### 4. Test Files (`/test/` directory)\n\n"
                "When available, provides:\n"
                "- **Example configurations**: Real-world parameter structures\n"
                "- **Usage patterns**: Idiomatic implementation approaches\n"
                "- **Test workflows**: Complete integration examples\n\n"
                "## Practical Implementation\n\n"
                "After analyzing the node definition, construct a conformant node object following the structure defined in the `n8n_sdk_python.models.workflows.Node` model. For detailed node object structure and examples, refer to the `node_json_usage_prompt`.\n\n"
                "This systematic approach ensures that workflow nodes are properly configured according to their design specifications, maximizing compatibility and reducing potential runtime errors."
            )
        }
    ]

@app.prompt()
def node_json_usage_prompt() -> list[dict[str, str]]:
    """
    Technical reference guide for constructing node objects in accordance with the n8n-sdk-python Node model.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Node Configuration Reference\n\n"
                "## Overview\n\n"
                "When utilizing the `create_workflow` or `update_workflow` operations, each node in the `nodes` array must strictly adhere to the `n8n_sdk_python.models.workflows.Node` model specification.\n\n"
                "## Prerequisites\n\n"
                "Prior to node construction, it is recommended to:\n\n"
                "1. Identify available node types via the `list_nodes` operation\n"
                "2. Examine complete node specifications via the `get_node_info` operation for your selected node type\n\n"
                "## Node Object Structure\n\n"
                "### Required Properties\n\n"
                "```json\n"
                "{\n"
                "  \"name\": \"ProcessApiData\",          // String: Unique instance identifier within workflow context\n"
                "  \"type\": \"n8n-nodes-base.httpRequest\", // String: Node type identifier from SDK registry\n"
                "  \"typeVersion\": 4.1,                 // Number: Version specification for node functionality\n"
                "  \"position\": [250.0, 300.0],         // Array: Canvas coordinates [x, y]\n"
                "  \"parameters\": {                      // Object: Configuration parameters\n"
                "    // Node-specific configuration (varies by node type)\n"
                "  }\n"
                "}\n"
                "```\n\n"
                "### Optional Properties\n\n"
                "```json\n"
                "{\n"
                "  \"credentials\": {                     // Object: Authentication references\n"
                "    \"oauthCredentialType\": {\n"
                "      \"id\": \"credentialId\",\n"
                "      \"name\": \"Production API Key\"\n"
                "    }\n"
                "  },\n"
                "  \"disabled\": false,                   // Boolean: Execution state\n"
                "  \"notes\": \"Fetches customer data\",    // String: Documentation\n"
                "  \"continueOnFail\": false,             // Boolean: Error handling behavior\n"
                "  \"onError\": \"stopWorkflow\",           // String: Error response strategy\n"
                "  \"retryOnFail\": false,                // Boolean: Retry configuration\n"
                "  \"maxTries\": 3,                       // Number: Maximum retry attempts\n"
                "  \"waitBetweenTries\": 5000            // Number: Milliseconds between retries\n"
                "}\n"
                "```\n\n"
                "## Parameters Object\n\n"
                "The `parameters` object structure varies significantly by node type. Always reference the specific node's definition via `get_node_info` to understand:\n\n"
                "1. **Required parameters** - Essential for node operation\n"
                "2. **Parameter data types** - Strings, numbers, booleans, arrays, or nested objects\n"
                "3. **Valid options** - Enumerated values or acceptable ranges\n"
                "4. **Default values** - Applied when not explicitly specified\n\n"
                "## Example: HTTP Request Node\n\n"
                "```json\n"
                "{\n"
                "  \"name\": \"FetchUserData\",\n"
                "  \"type\": \"n8n-nodes-base.httpRequest\",\n"
                "  \"typeVersion\": 4.1,\n"
                "  \"position\": [340.0, 400.0],\n"
                "  \"parameters\": {\n"
                "    \"url\": \"https://api.example.com/users\",\n"
                "    \"method\": \"GET\",\n"
                "    \"authentication\": \"predefinedCredentialType\",\n"
                "    \"sendHeaders\": true,\n"
                "    \"headerParameters\": {\n"
                "      \"parameters\": [\n"
                "        {\n"
                "          \"name\": \"Content-Type\",\n"
                "          \"value\": \"application/json\"\n"
                "        }\n"
                "      ]\n"
                "    },\n"
                "    \"options\": {\n"
                "      \"redirect\": {\n"
                "        \"follow\": true,\n"
                "        \"maxRedirects\": 5\n"
                "      },\n"
                "      \"responseFormat\": \"json\",\n"
                "      \"timeout\": 10000\n"
                "    }\n"
                "  },\n"
                "  \"credentials\": {\n"
                "    \"httpBasicAuth\": {\n"
                "      \"id\": \"7\",\n"
                "      \"name\": \"API Authentication\"\n"
                "    }\n"
                "  }\n"
                "}\n"
                "```\n\n"
                "## Best Practices\n\n"
                "1. **Unique Names**: Ensure each node has a unique `name` value within the workflow\n"
                "2. **Consistent Types**: Use exact type identifiers from the `list_nodes` operation\n"
                "3. **Version Alignment**: Specify the correct `typeVersion` for compatibility\n"
                "4. **Parameter Validation**: Verify parameter structure against node definition\n"
                "5. **Position Planning**: Assign non-overlapping positions for visual clarity\n\n"
                "To further explore available node types and their configurations, use the `list_nodes` and `get_node_info` operations."
            )
        }
    ]

@app.prompt()
def workflow_connection_prompt() -> list[dict[str, str]]:
    """
    Technical reference for configuring data flow connections between workflow nodes.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Workflow Connection Configuration\n\n"
                "## Overview\n\n"
                "The `connections` parameter in workflow operations defines the data flow topology between nodes. This structure maps precisely to the connection schema in the `n8n_sdk_python.models.workflows` module.\n\n"
                "## Connection Structure\n\n"
                "```json\n"
                "{\n"
                "  \"SourceNode\": {                       // Source node name (string)\n"
                "    \"main\": [                           // Output type (typically \"main\")\n"
                "      [                                   // Array of connections from output index 0\n"
                "        {\n"
                "          \"node\": \"TargetNode\",         // Target node name (string)\n"
                "          \"type\": \"main\",               // Input type (typically \"main\")\n"
                "          \"index\": 0                     // Target input index (integer)\n"
                "        }\n"
                "      ]\n"
                "    ]\n"
                "  }\n"
                "}\n"
                "```\n\n"
                "## Key Concepts\n\n"
                "1. **Outer Object**: Keyed by source node names\n"
                "2. **Connection Type**: Typically `\"main\"` for standard data flow\n"
                "3. **Output Port Array**: Each source node can have multiple output ports\n"
                "   - First level array represents different output ports (indices)\n"
                "   - Second level array represents connections from a specific output port\n"
                "4. **Connection Object**: Defines a single connection with three properties:\n"
                "   - `node`: Target node name (must match a node's `name` in the `nodes` array)\n"
                "   - `type`: Connection type (typically `\"main\"`)\n"
                "   - `index`: Target input port index (typically `0` for primary input)\n\n"
                "## Connection Patterns\n\n"
                "### Linear Flow\n"
                "```json\n"
                "{\n"
                "  \"NodeA\": {\n"
                "    \"main\": [[\n"
                "      { \"node\": \"NodeB\", \"type\": \"main\", \"index\": 0 }\n"
                "    ]]\n"
                "  },\n"
                "  \"NodeB\": {\n"
                "    \"main\": [[\n"
                "      { \"node\": \"NodeC\", \"type\": \"main\", \"index\": 0 }\n"
                "    ]]\n"
                "  }\n"
                "}\n"
                "```\n\n"
                "### Branch Flow (1:N)\n"
                "```json\n"
                "{\n"
                "  \"NodeA\": {\n"
                "    \"main\": [[\n"
                "      { \"node\": \"NodeB\", \"type\": \"main\", \"index\": 0 },\n"
                "      { \"node\": \"NodeC\", \"type\": \"main\", \"index\": 0 }\n"
                "    ]]\n"
                "  }\n"
                "}\n"
                "```\n\n"
                "### Multi-Output Flow\n"
                "For nodes with multiple outputs (e.g., IF nodes with true/false branches):\n"
                "```json\n"
                "{\n"
                "  \"IF_Node\": {\n"
                "    \"main\": [\n"
                "      [{ \"node\": \"TruePathNode\", \"type\": \"main\", \"index\": 0 }],  // Output 0 (true)\n"
                "      [{ \"node\": \"FalsePathNode\", \"type\": \"main\", \"index\": 0 }]   // Output 1 (false)\n"
                "    ]\n"
                "  }\n"
                "}\n"
                "```\n\n"
                "## Best Practices\n\n"
                "1. **Name Consistency**: Ensure node names in connections exactly match those in the `nodes` array\n"
                "2. **Index Management**: Use appropriate output and input indices for nodes with multiple ports\n"
                "3. **Topology Validation**: Avoid circular references that may cause infinite loops\n"
                "4. **Connection Completion**: Ensure all non-terminal nodes have outgoing connections\n"
                "5. **Input Validation**: Verify target nodes accept the data type produced by source nodes\n\n"
                "## Implementation Notes\n\n"
                "- An empty object `{}` signifies no connections between nodes\n"
                "- Node names are case-sensitive\n"
                "- When updating workflows, the entire connections object must be provided, as partial updates are not supported\n\n"
                "For specific node connection requirements, consult the node documentation via the `get_node_info` operation."
            )
        }
    ]

@app.prompt()
def tag_management_prompt() -> list[dict[str, str]]:
    """
    Technical reference guide for workflow tag management operations.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Workflow Tag Management\n\n"
                "## Overview\n\n"
                "Tags provide an organizational framework for workflows in n8n, enabling effective categorization, filtering, and management. The tag structure conforms to the `n8n_sdk_python.models.workflows.Tag` model specification.\n\n"
                "## Tag Object Schema\n\n"
                "```json\n"
                "{\n"
                "  \"id\": \"c8b92a70-da55-4fff-8df9-5120a9a68abc\",  // String: Unique identifier\n"
                "  \"name\": \"Production\",                           // String: Display name\n"
                "  \"createdAt\": \"2025-01-15T09:43:11.000Z\",       // String: ISO timestamp (optional)\n"
                "  \"updatedAt\": \"2025-01-15T09:43:11.000Z\"        // String: ISO timestamp (optional)\n"
                "}\n"
                "```\n\n"
                "## Available Operations\n\n"
                "### Retrieving Tags\n\n"
                "#### System Tag Registry\n\n"
                "Access the complete tag registry using the `n8n:/tags` resource:\n\n"
                "```\n"
                "// Returns all available tags in the system\n"
                "{\n"
                "  \"tags\": [\n"
                "    { \"id\": \"tag-id-1\", \"name\": \"Production\" },\n"
                "    { \"id\": \"tag-id-2\", \"name\": \"Development\" },\n"
                "    // Additional tags...\n"
                "  ]\n"
                "}\n"
                "```\n\n"
                "#### Workflow-Specific Tags\n\n"
                "1. **Via Workflow Lists**:\n"
                "   - The `list_workflows` operation returns tags associated with each workflow\n"
                "   - Example return structure:\n"
                "   ```\n"
                "   {\n"
                "     \"status\": \"success\",\n"
                "     \"workflows\": [\n"
                "       {\n"
                "         \"id\": \"workflow-id\",\n"
                "         \"name\": \"Customer Data Processor\",\n"
                "         \"tags\": [{ \"id\": \"tag-id\", \"name\": \"Production\" }]\n"
                "       }\n"
                "     ]\n"
                "   }\n"
                "   ```\n\n"
                "2. **Via Specific Workflow**:\n"
                "   - The `get_workflow` operation provides tag data for a single workflow\n"
                "   - Tags appear in the `workflow.tags` array in the response\n\n"
                "### Managing Tags\n\n"
                "#### Current Implementation Status\n\n"
                "The MCP server currently provides tag retrieval capabilities, but direct tag management operations (create, update, assign, remove) must be performed via the core n8n API. For tag assignment or removal:\n\n"
                "1. Retrieve the workflow using `get_workflow`\n"
                "2. Note the current tag configuration\n"
                "3. Perform tag modifications via the n8n SDK client directly, as direct tag modification is not yet exposed through MCP tools\n\n"
                "#### Implementation Strategy\n\n"
                "To modify workflow tags, you would typically:\n\n"
                "1. Obtain the complete list of system tags via `n8n:/tags`\n"
                "2. Identify tag IDs for required tags\n"
                "3. Use the n8n SDK's `update_workflow_tags` method with the appropriate workflow ID and tag ID array\n\n"
                "## Best Practices\n\n"
                "1. **Consistent Naming**: Establish clear tag naming conventions (e.g., environment, purpose, department)\n"
                "2. **Tag Reuse**: Prefer existing tags over creating new ones with similar names\n"
                "3. **Minimal Assignment**: Apply only relevant tags to maintain clean categorization\n"
                "4. **Hierarchical Structure**: Consider namespace prefixes for related tags (e.g., \"env:prod\", \"dept:finance\")\n\n"
                "For specific tag management operations beyond the current capabilities, please indicate your requirements for assistance with the appropriate n8n SDK implementation."
            )
        }
    ]

@app.prompt()
def workflow_settings_prompt() -> list[dict[str, str]]:
    """
    Technical reference for workflow execution settings configuration based on the WorkflowSettings model.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Workflow Settings Configuration\n\n"
                "## Overview\n\n"
                "The `settings` parameter in workflow operations defines execution behavior and data retention policies. This configuration adheres to the `n8n_sdk_python.models.workflows.WorkflowSettings` model specification.\n\n"
                "## Settings Schema\n\n"
                "```json\n"
                "{\n"
                "  \"saveExecutionProgress\": true,          // Boolean: Whether to record node-by-node execution data\n"
                "  \"saveDataErrorExecution\": \"all\",        // String: Error data retention strategy (\"all\"|\"none\"|node-id)\n"
                "  \"saveDataSuccessExecution\": \"all\",      // String: Success data retention strategy (\"all\"|\"none\"|node-id)\n"
                "  \"saveManualExecutions\": true,           // Boolean: Whether to save manual execution records\n"
                "  \"executionTimeout\": 3600,               // Integer: Maximum execution time in seconds\n"
                "  \"timezone\": \"UTC\",                      // String: IANA timezone identifier\n"
                "  \"errorWorkflow\": \"errorHandlerId\",      // String: ID of workflow to trigger on error (optional)\n"
                "  \"executionOrder\": \"v1\"                  // String: Execution order strategy (typically \"v1\")\n"
                "}\n"
                "```\n\n"
                "## Core Configuration Parameters\n\n"
                "### Data Persistence Controls\n\n"
                "- **`saveExecutionProgress`** (boolean)\n"
                "  - Controls whether detailed execution progress is recorded\n"
                "  - Default: `true`\n"
                "  - Impact: Allows execution visualization and debugging\n\n"
                "- **`saveDataErrorExecution`** (string)\n"
                "  - Controls data retention for failed executions\n"
                "  - Values:\n"
                "    - `\"all\"`: Save all node input/output data\n"
                "    - `\"none\"`: Don't save any node data\n"
                "    - `\"node-id\"`: Save data only for the specified node\n"
                "  - Default: `\"all\"`\n"
                "  - Impact: Storage usage and debugging capabilities\n\n"
                "- **`saveDataSuccessExecution`** (string)\n"
                "  - Controls data retention for successful executions\n"
                "  - Values: Same as `saveDataErrorExecution`\n"
                "  - Default: `\"all\"`\n"
                "  - Impact: Storage usage and execution analysis\n\n"
                "- **`saveManualExecutions`** (boolean)\n"
                "  - Controls whether manual execution records are saved\n"
                "  - Default: `true`\n"
                "  - Impact: Historical record of user-triggered runs\n\n"
                "### Execution Controls\n\n"
                "- **`executionTimeout`** (integer)\n"
                "  - Maximum runtime in seconds before forced termination\n"
                "  - Default: `3600` (1 hour)\n"
                "  - Range: `1` to system maximum\n"
                "  - Impact: Resource protection and runaway execution prevention\n\n"
                "- **`timezone`** (string)\n"
                "  - IANA timezone identifier for schedule-based operations\n"
                "  - Default: `\"UTC\"` (standardized in this implementation)\n"
                "  - Examples: `\"America/New_York\"`, `\"Europe/London\"`, `\"Asia/Tokyo\"`\n"
                "  - Impact: Scheduling accuracy and timestamp interpretation\n\n"
                "- **`errorWorkflow`** (string, optional)\n"
                "  - Workflow ID to trigger when execution fails\n"
                "  - Format: Valid workflow ID string\n"
                "  - Impact: Automated error handling and recovery\n\n"
                "## Usage Guidelines\n\n"
                "### Creation Context\n\n"
                "When used with `create_workflow`, omitting the `settings` parameter applies these defaults:\n\n"
                "```json\n"
                "{\n"
                "  \"saveExecutionProgress\": true,\n"
                "  \"saveManualExecutions\": true,\n"
                "  \"saveDataErrorExecution\": \"all\",\n"
                "  \"saveDataSuccessExecution\": \"all\",\n"
                "  \"executionTimeout\": 3600,\n"
                "  \"timezone\": \"UTC\"\n"
                "}\n"
                "```\n\n"
                "### Update Context\n\n"
                "When used with `update_workflow`:\n\n"
                "1. Only include parameters you wish to modify\n"
                "2. Omitted parameters retain their existing values\n"
                "3. To reset a parameter to its default, explicitly specify the default value\n\n"
                "## Best Practices\n\n"
                "1. **Resource Optimization**: For large-scale workflows, consider using `\"none\"` for `saveDataSuccessExecution` to reduce storage usage\n"
                "2. **Timeout Calibration**: Set `executionTimeout` based on expected execution duration plus a reasonable buffer\n"
                "3. **Timezone Consistency**: Use a consistent timezone strategy across related workflows\n"
                "4. **Scheduled Workflows**: Always explicitly set the `timezone` parameter for scheduled workflows\n"
                "5. **Error Handling**: Implement error workflows for critical production systems\n\n"
                "For specific execution behavior requirements, consider your workflow's performance profile, data volume, and operational context."
            )
        }
    ]

@app.prompt()
def workflow_static_data_prompt() -> list[dict[str, str]]:
    """
    Technical reference for workflow static data configuration aligned with WorkflowStaticData model.
    """
    return [
        {
            "role": "assistant",
            "content": (
                "# Workflow Static Data Configuration\n\n"
                "## Overview\n\n"
                "The `static_data` parameter enables persistent state management between workflow executions. This configuration maps to the `n8n_sdk_python.models.workflows.WorkflowStaticData` model and provides workflow-level state persistence.\n\n"
                "## Schema Definition\n\n"
                "```json\n"
                "{\n"
                "  \"lastId\": 1042,                    // Integer: Incrementing counter or sequence\n"
                "  \"customProperty\": \"value\"          // Any: Custom properties as needed\n"
                "}\n"
                "```\n\n"
                "## Core Properties\n\n"
                "### Standard Properties\n\n"
                "- **`lastId`** (integer, optional)\n"
                "  - Purpose: Tracking sequence numbers or unique identifiers\n"
                "  - Pattern: Typically incremented with each execution\n"
                "  - Default: None (not automatically initialized)\n\n"
                "### Custom Properties\n\n"
                "The `WorkflowStaticData` model is extensible and can accommodate custom properties beyond the predefined fields. Common use cases include:\n\n"
                "- **Timestamp tracking**: Last execution time or data sync point\n"
                "- **State flags**: Configuration toggles or operational modes\n"
                "- **Counters**: Aggregation values or throttling trackers\n"
                "- **Reference data**: Cached lookup values or configuration settings\n\n"
                "## Implementation Patterns\n\n"
                "### Sequence Generator\n\n"
                "```json\n"
                "// Initial state\n"
                "{ \"lastId\": 0 }\n"
                "\n"
                "// After first execution\n"
                "{ \"lastId\": 1 }\n"
                "```\n\n"
                "### State Machine\n\n"
                "```json\n"
                "// Managing workflow processing phases\n"
                "{ \n"
                "  \"processingStage\": \"dataValidation\",\n"
                "  \"validatedRecords\": 145,\n"
                "  \"lastProcessedTimestamp\": \"2025-01-15T08:30:00Z\"\n"
                "}\n"
                "```\n\n"
                "### Throttling Counter\n\n"
                "```json\n"
                "// API rate limiting management\n"
                "{\n"
                "  \"apiCallsToday\": 487,\n"
                "  \"dailyQuota\": 1000,\n"
                "  \"quotaResetDate\": \"2025-01-16T00:00:00Z\"\n"
                "}\n"
                "```\n\n"
                "## Access Mechanisms\n\n"
                "In n8n workflow nodes, static data is accessible via the workflow context:\n\n"
                "```javascript\n"
                "// In a Function node\n"
                "const lastId = $workflow.staticData.lastId || 0;\n"
                "const nextId = lastId + 1;\n"
                "\n"
                "// Update the static data\n"
                "$workflow.staticData.lastId = nextId;\n"
                "```\n\n"
                "## Usage Guidelines\n\n"
                "### Creation Context\n\n"
                "When used with `create_workflow`, the `static_data` parameter initializes the persistent state:\n"
                "```json\n"
                "{\n"
                "  \"lastId\": 0,\n"
                "  \"initialized\": true,\n"
                "  \"createdAt\": \"2025-01-15T12:00:00Z\"\n"
                "}\n"
                "```\n\n"
                "### Update Context\n\n"
                "When used with `update_workflow`, the `static_data` parameter replaces the entire static data object. To preserve existing values while updating specific properties, first retrieve the current workflow, then modify only the targeted properties.\n\n"
                "## Limitations and Considerations\n\n"
                "1. **Data Volume**: Static data should remain small (recommended <10KB)\n"
                "2. **Persistence**: Changes to static data via the API are immediate and persistent\n"
                "3. **Complexity**: For complex state management, consider external databases\n"
                "4. **Concurrency**: Be aware of potential race conditions with parallel executions\n"
                "5. **Initialization**: Static data is not automatically initialized; explicitly set initial values\n\n"
                "For advanced state management or large datasets, consider using dedicated database nodes or external storage services rather than expanding static data beyond its intended scope."
            )
        }
    ]
